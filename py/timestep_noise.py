"""
ZImage/Lumina2 é‡‡æ ·æ‰°åŠ¨èŠ‚ç‚¹

è¿™ä¸ªèŠ‚ç‚¹å¯ä»¥åœ¨é‡‡æ ·è¿‡ç¨‹ä¸­æ³¨å…¥å™ªå£°æ‰°åŠ¨ï¼Œ
æ‰“ç ´æ¨¡å‹çš„åŒè´¨åŒ–è¾“å‡ºï¼Œä½¿ä¸åŒç§å­èƒ½äº§ç”Ÿæ›´æ˜æ˜¾çš„å·®å¼‚ã€‚
"""

import torch
import torch.nn.functional as F
import logging


class ZImageTimestepNoise:
    """
    å¯¹ timestep/sigma æ·»åŠ å™ªå£°æ‰°åŠ¨
    è¿™ä¼šæ”¹å˜æ¨¡å‹å¯¹å½“å‰å»å™ªæ­¥éª¤çš„æ„ŸçŸ¥ï¼Œäº§ç”Ÿä¸åŒçš„è¾“å‡º
    
    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    - sigma: é€‚ç”¨äºä¼ ç»Ÿæ‰©æ•£æ¨¡å‹ï¼Œä½¿ç”¨ä¹˜æ€§å™ªå£°
    - flow: é€‚ç”¨äº Flow Matching æ¨¡å‹ï¼ˆå¦‚ ZImage/Lumina2ï¼‰ï¼Œä½¿ç”¨åŠ æ€§å™ªå£°
    """
    
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "model": ("MODEL",),
                "sigmas": ("SIGMAS",),
                "mode": (["sigma", "flow"], {
                    "default": "flow",
                    "tooltip": "sigma: ä¼ ç»Ÿæ‰©æ•£æ¨¡å‹ï¼ˆä¹˜æ€§å™ªå£°ï¼‰; flow: Flow Matching æ¨¡å‹ï¼ˆåŠ æ€§å™ªå£°ï¼‰"
                }),
                "noise_strength": ("FLOAT", {
                    "default": 0.05, 
                    "min": 0.0, 
                    "max": 2.0, 
                    "step": 0.01,
                    "tooltip": "å™ªå£°å¼ºåº¦"
                }),
                "seed": ("INT", {
                    "default": 0, 
                    "min": 0, 
                    "max": 0xffffffffffffffff,
                    "tooltip": "å™ªå£°ç§å­"
                }),
                "start_percent": ("FLOAT", {
                    "default": 0.0,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.01,
                    "tooltip": "å¼€å§‹åº”ç”¨å™ªå£°çš„é‡‡æ ·è¿›åº¦ (0.0 = å¼€å§‹)"
                }),
                "end_percent": ("FLOAT", {
                    "default": 0.5,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.01,
                    "tooltip": "åœæ­¢åº”ç”¨å™ªå£°çš„é‡‡æ ·è¿›åº¦ (1.0 = ç»“æŸ)"
                }),
            },
            "optional": {
                "mask": ("MASK",),
            }
        }

    RETURN_TYPES = ("MODEL",)
    FUNCTION = "patch"
    CATEGORY = "ğŸˆLAOGOU/Sampling Utils"
    DESCRIPTION = "å¯¹ timestep æ·»åŠ å™ªå£°æ‰°åŠ¨ï¼Œæ”¹å˜æ¨¡å‹å¯¹å»å™ªæ­¥éª¤çš„æ„ŸçŸ¥ã€‚sigma æ¨¡å¼é€‚ç”¨äºä¼ ç»Ÿæ‰©æ•£æ¨¡å‹ï¼Œflow æ¨¡å¼é€‚ç”¨äº Flow Matching æ¨¡å‹ï¼ˆå¦‚ ZImage/Lumina2ï¼‰ã€‚å¯é€‰é®ç½©é™åˆ¶å½±å“åŒºåŸŸã€‚"

    def patch(self, model, sigmas, mode, noise_strength, seed, start_percent, end_percent, mask=None):
        m = model.clone()
        
        if noise_strength <= 0:
            return (m,)
        
        # å°† sigmas è½¬æ¢ä¸º list ä»¥ä¾¿æŸ¥æ‰¾
        sigma_list = sigmas.tolist()
        total_steps = len(sigma_list) - 1  # æœ€åä¸€ä¸ªæ˜¯ 0
        
        stored_mode = mode
        stored_strength = noise_strength
        stored_seed = seed
        stored_start = start_percent
        stored_end = end_percent
        stored_sigmas = sigma_list
        stored_total_steps = total_steps
        stored_mask = mask
        step_counter = [0]
        
        def unet_wrapper(apply_model_func, args):
            input_x = args["input"]
            timestep = args["timestep"]
            c = args["c"]
            
            step_counter[0] += 1
            current_step = step_counter[0]
            
            # è·å–å½“å‰ sigma å€¼
            sigma_val = float(timestep[0]) if timestep.dim() > 0 else float(timestep)
            
            # åœ¨ sigma_list ä¸­æŸ¥æ‰¾å½“å‰ sigma çš„ä½ç½®æ¥ç¡®å®šè¿›åº¦
            min_diff = float('inf')
            matched_idx = 0
            for i, s in enumerate(stored_sigmas):
                diff = abs(s - sigma_val)
                if diff < min_diff:
                    min_diff = diff
                    matched_idx = i
            
            # è®¡ç®—è¿›åº¦
            progress = matched_idx / stored_total_steps if stored_total_steps > 0 else 0.0
            progress = max(0.0, min(1.0, progress))
            
            # æ£€æŸ¥æ˜¯å¦åœ¨æŒ‡å®šèŒƒå›´å†…
            in_range = progress >= stored_start and progress <= stored_end
            
            # å‡†å¤‡é®ç½©ï¼ˆå¦‚æœæœ‰ï¼‰
            latent_mask = None
            if stored_mask is not None:
                mask_tensor = stored_mask
                if mask_tensor.dim() == 2:
                    mask_tensor = mask_tensor.unsqueeze(0)
                latent_h, latent_w = input_x.shape[2], input_x.shape[3]
                latent_mask = F.interpolate(
                    mask_tensor.unsqueeze(1),
                    size=(latent_h, latent_w),
                    mode='bilinear',
                    align_corners=False
                )
                if latent_mask.shape[0] == 1 and input_x.shape[0] > 1:
                    latent_mask = latent_mask.expand(input_x.shape[0], -1, -1, -1)
                latent_mask = latent_mask.to(device=input_x.device, dtype=input_x.dtype)
            
            # è®¡ç®—å™ªå£°ï¼ˆæ— è®ºæ˜¯å¦åœ¨èŒƒå›´å†…éƒ½è®¡ç®—ï¼Œç”¨äºè°ƒè¯•æ˜¾ç¤ºï¼‰
            generator = torch.Generator(device=timestep.device)
            generator.manual_seed(stored_seed + current_step)
            
            t_orig = float(timestep[0]) if timestep.dim() > 0 else float(timestep)
            
            if stored_mode == "sigma":
                noise_factor = 1.0 + (torch.rand(1, generator=generator, device=timestep.device).item() - 0.5) * stored_strength
                noisy_timestep = timestep * noise_factor
            else:  # flow æ¨¡å¼
                # è®¡ç®—å¯ç”¨ç©ºé—´
                headroom_up = 1.0 - t_orig    # å‘ä¸Šçš„ç©ºé—´
                headroom_down = t_orig - 0.0  # å‘ä¸‹çš„ç©ºé—´
                
                # ç¡®å®šå®é™…å¯ç”¨çš„å™ªå£°èŒƒå›´
                actual_up = min(stored_strength, headroom_up)
                actual_down = min(stored_strength, headroom_down)
                
                # ç”Ÿæˆ [0, 1] éšæœºæ•°ï¼Œç„¶åæ˜ å°„åˆ° [-actual_down, +actual_up]
                raw = torch.rand(1, generator=generator, device=timestep.device).item()
                total_range = actual_down + actual_up
                
                if total_range > 1e-6:
                    # æ˜ å°„åˆ°å¯ç”¨èŒƒå›´ï¼šraw=0 -> -actual_down, raw=1 -> +actual_up
                    actual_delta = raw * total_range - actual_down
                else:
                    actual_delta = 0.0
                
                noisy_timestep = timestep + actual_delta
                # å®‰å…¨ clamp
                noisy_timestep = torch.clamp(noisy_timestep, 0.0, 1.0)
            
            # è·å–æ•°å€¼ç”¨äºæ—¥å¿—
            t_noisy = float(noisy_timestep[0]) if noisy_timestep.dim() > 0 else float(noisy_timestep)
            delta = t_noisy - t_orig
            
            # è°ƒè¯•è¾“å‡º
            if current_step <= 5:
                status = "âœ“ APPLIED" if in_range else "âœ— SKIPPED"
                has_mask = "mask=YES" if latent_mask is not None else "mask=NO"
                if stored_mode == "flow":
                    logging.info(f"[ZImageTimestepNoise] step={current_step}/{stored_total_steps} | progress={progress:.2f} | range=[{stored_start:.2f}, {stored_end:.2f}] | {status}")
                    logging.info(f"[ZImageTimestepNoise]   timestep: {t_orig:.6f} -> {t_noisy:.6f} (delta={delta:+.6f}) | headroom=[â†“{headroom_down:.3f}, â†‘{headroom_up:.3f}] | {has_mask}")
                else:
                    logging.info(f"[ZImageTimestepNoise] step={current_step}/{stored_total_steps} | progress={progress:.2f} | range=[{stored_start:.2f}, {stored_end:.2f}] | {status}")
                    logging.info(f"[ZImageTimestepNoise]   timestep: {t_orig:.6f} -> {t_noisy:.6f} (delta={delta:+.6f}) | factor={noise_factor:.4f} | {has_mask}")
            
            if not in_range:
                # ä¸åœ¨èŒƒå›´å†…ï¼Œä½¿ç”¨åŸå§‹ timestep
                return apply_model_func(input_x, timestep, **c)
            
            # åœ¨èŒƒå›´å†…ï¼Œåº”ç”¨å™ªå£°
            if latent_mask is not None:
                # è®¡ç®—ä¸¤ç§ timestep ä¸‹çš„ç»“æœå¹¶æ··åˆ
                result_original = apply_model_func(input_x, timestep, **c)
                result_noisy = apply_model_func(input_x, noisy_timestep, **c)
                result = result_original * (1 - latent_mask) + result_noisy * latent_mask
                return result
            else:
                # æ— é®ç½©ï¼Œç›´æ¥ä½¿ç”¨æ‰°åŠ¨åçš„ timestep
                return apply_model_func(input_x, noisy_timestep, **c)
            
            return apply_model_func(input_x, timestep, **c)
        
        m.set_model_unet_function_wrapper(unet_wrapper)
        
        return (m,)


# æ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "ZImageTimestepNoise": ZImageTimestepNoise,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ZImageTimestepNoise": "ZImage Timestep Noise",
}
